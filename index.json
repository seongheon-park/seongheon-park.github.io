[{"authors":null,"categories":null,"content":"I’m a M.S. Candidate working with Prof.Kwanghoon Sohn at the Department of Electrical and Electronic Engineering at Yonsei University, Republic of Korea. I’m interested in deploying Computer Vision and Machine Learning models to the real Open-World which contains situations that are dynamic, vast, never-before-seen, and unpredictable.\n","date":1554595200,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1554595200,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"I’m a M.S. Candidate working with Prof.Kwanghoon Sohn at the Department of Electrical and Electronic Engineering at Yonsei University, Republic of Korea. I’m interested in deploying Computer Vision and Machine Learning models to the real Open-World which contains situations that are dynamic, vast, never-before-seen, and unpredictable.","tags":null,"title":"Seongheon Park","type":"authors"},{"authors":[],"categories":null,"content":" Click on the Slides button above to view the built-in slides feature. Slides can be added in a few ways:\nCreate slides using Wowchemy’s Slides feature and link using slides parameter in the front matter of the talk file Upload an existing slide deck to static/ and link using url_slides parameter in the front matter of the talk file Embed your slides (e.g. Google Slides) or presentation video on this page using shortcodes. Further event details, including page elements such as image galleries, can be added to the body of this page.\n","date":1906549200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1906549200,"objectID":"a8edef490afe42206247b6ac05657af0","permalink":"https://seongheon-park.github.io/talk/example-talk/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/example-talk/","section":"event","summary":"An example talk using Wowchemy's Markdown slides feature.","tags":[],"title":"Example Talk","type":"event"},{"authors":null,"categories":null,"content":" ","date":1690675200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1690675200,"objectID":"21347c7d0a801e5f98f3fdfa9ecc13f7","permalink":"https://seongheon-park.github.io/post/iccv2023/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/post/iccv2023/","section":"post","summary":"One paper about compositional zero-shot learning is accepted by [**ICCV 2023**](https://iccv2023.thecvf.com/)!","tags":null,"title":"","type":"post"},{"authors":null,"categories":null,"content":" ","date":1676764800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1676764800,"objectID":"aa7d5409f1fa20125c5c9062f861b055","permalink":"https://seongheon-park.github.io/post/cvpr2023/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/post/cvpr2023/","section":"post","summary":"One paper about cross-domain person re-identification is accepted by [**CVPR 2023**](https://cvpr2023.thecvf.com/)!","tags":null,"title":"","type":"post"},{"authors":null,"categories":null,"content":" ","date":1666828800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1666828800,"objectID":"efb5bb95fcfd51e9f627eccc4b72a45c","permalink":"https://seongheon-park.github.io/post/wacv2023_1/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/post/wacv2023_1/","section":"post","summary":"One paper about weakly-supervised video anomaly detection is accepted by [**WACV 2023**](https://wacv2023.thecvf.com/home)!","tags":null,"title":"","type":"post"},{"authors":null,"categories":null,"content":" ","date":1666828800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1666828800,"objectID":"e2f0ea77ad5f1e556c2b624de627dd87","permalink":"https://seongheon-park.github.io/post/wacv2023_2/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/post/wacv2023_2/","section":"post","summary":"One paper about zero-shot video grounding is accepted by [**WACV 2023**](https://wacv2023.thecvf.com/home)!","tags":null,"title":"","type":"post"},{"authors":null,"categories":null,"content":"Research on artificial intelligence technology that can mimic various human abilities by using image/video, voice/audio, and text/natural language, which are the basis of artificial intelligence.\nComplex and comprehensive scene understanding using multimodal signals, user understanding, virtual space-time synthesis technology, and development of a general-purpose social artificial intelligence system through the integration of these technologies.\n","date":1646092800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1646092800,"objectID":"e9f2758a8cec6fe970889b4e8ea07727","permalink":"https://seongheon-park.github.io/project/project4/","publishdate":"2022-03-01T00:00:00Z","relpermalink":"/project/project4/","section":"project","summary":"Funded by Yonsei University-Yonsei Signature Research Cluster","tags":["Deep Learning"],"title":"Development of Multimodal-based General-purpose Social Artificial Intelligence Technology","type":"project"},{"authors":null,"categories":null,"content":"Developing source technology for complext scene understanding and future prediction through artificial intelligence neural networks.\nIntegrating complementary information in multiple ways through convergence between multimodal data.\nDescribing human social intelligence to develop complex relationship reasoning skills bewteen multiple objects and surrounding environments through learning of a social AI.\n","date":1614556800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1614556800,"objectID":"68fe1e900090392e3d2a97574964bc5a","permalink":"https://seongheon-park.github.io/project/project3/","publishdate":"2021-03-01T00:00:00Z","relpermalink":"/project/project3/","section":"project","summary":"Funded by Ministry of Science and ICT, Mid-Level Research","tags":["Deep Learning"],"title":"Development of Complex Situational Awareness and Prediction Technology through Multi-modal Data Fusion and Social Artificial Intelligence","type":"project"},{"authors":["Seongheon Park"],"categories":null,"content":" Create your slides in Markdown - click the Slides button to check out the example. Supplementary notes can be added here, including code, math, and images.\n","date":1554595200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1554595200,"objectID":"557dc08fd4b672a0c08e0a8cf0c9ff7d","permalink":"https://seongheon-park.github.io/publication/preprint/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/preprint/","section":"publication","summary":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":["Source Themes"],"title":"An example preprint / working paper","type":"publication"},{"authors":null,"categories":null,"content":"Development of emotion recognition technology through video-based interaction of emotion/action/environment.\nDevelopment of human-centric comprehensive video scene analysis and action recognition technology.\nDevelopment of environmental change prediction technology through comprehensive situational recognition.\n","date":1519862400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1519862400,"objectID":"9b74b6d80c74c11210b876d3c28bd186","permalink":"https://seongheon-park.github.io/project/project1/","publishdate":"2018-03-01T00:00:00Z","relpermalink":"/project/project1/","section":"project","summary":"Funded by Korea Institute of Science and Technology (KIST)","tags":["Deep Learning"],"title":"Deep Identification and Tracking of Missing Persons in Heterogeneous CCTV","type":"project"},{"authors":["Seongheon Park","Robert Ford"],"categories":null,"content":" Click the Cite button above to demo the feature to enable visitors to import publication metadata into their reference management software. Create your slides in Markdown - click the Slides button to check out the example. Supplementary notes can be added here, including code, math, and images.\n","date":1441065600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1441065600,"objectID":"966884cc0d8ac9e31fab966c4534e973","permalink":"https://seongheon-park.github.io/publication/journal-article/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/journal-article/","section":"publication","summary":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":["Source Themes"],"title":"An example journal article","type":"publication"}]